<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="MADiff: Motion-Aware Mamba Diffusion Models for Hand Trajectory Prediction on Egocentric Videos.">
  <meta name="keywords" content="Hand Trajectory Prediction, Egocentric Vision, Hand-Object Interaction">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Website: LLMs as Efficient Reward Function Searchers for Custom-Environment MORL</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/icon.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>



<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">LLMs as Efficient Reward Function Searchers for Custom-Environment MORL</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://360zmem.github.io/">Guanwen Xie</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://2870325142.github.io/MiMi-Xu.github.io/">Jingzehua Xu</a><sup>1</sup>,</span>

            <span class="author-block">
              <a href="https://yyysjz1997.github.io/">Yiyuan Yang</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://github.com/Xiboxtg/">Yimian Ding</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="about:blank">Shuai Zhang</a><sup>3</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Massachusetts Institute of Technology,</span>
            <span class="author-block"><sup>2</sup>University of Oxford,</span>
            <span class="author-block"><sup>3</sup>New Jersey Institute of Technology</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2409.02428"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/360ZMEM/LLMRsearcher-code"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section" style="text-align: center;" >
  <h2 class="title is-3" style="text-align: center;">
    ERFSL Architecture & Example Prompts
  </h2>
  <img src="./static/images/archi.png"
       class="architecture-image"
       alt="architecture-image image."
       style="width: 60%; display: block; margin: 0 auto;"/>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Introduction</h2>
        <div class="content has-text-justified">
          <p>
            Our approach is based on these observations:
          </p>
          <ul>
            <li>It's hard to design and balance reward components for multi-objective reinforcement learning (MORL). </li>
            <li>It's hard for LLMs to design intricate reward functions on trial-and-error exploration and rectify wrong reward functions through implicit feedback. </li>
            <li>LLMs, especially those on a smaller scale, have a severe decline in comprehension in long contexts.</li>
            <li>LLMs are adept at summarizing and heuristically generating code with specific and clear task contexts, yet they are less proficient in tackling numerical contexts.</li>
          </ul>
          <p>
            We propose <em>ERFSL</em>, an efficient reward function searcher using LLMs, which enables LLMs to be effective white-box searchers and highlights their advanced semantic understanding capabilities.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>




<section class="section" style="text-align: center;" >
  <div class="container is-max-desktop">
  <h2 class="title is-3" style="text-align: center;">
    Experimental Results & Example Case Studies
  </h2>
  <img src="./static/images/fin5.png"
       class="architecture-image"
       alt="architecture-image image."
       style="width: 50%; display: block; margin: 0 auto;"/>
       <p>The reward critic can effectively detect various errors and
        then rewrite reward components based on the description and
        variables of the Env class. 
       For each component, only one iteration is needed to obtain the correct feedback results.</p>
       <br></br>
  <img src="./static/images/fin1.png"
       class="architecture-image"
       alt="architecture-image image."
       style="width: 45%; display: block; margin: 0 auto;"/>
       <p>The reward critic can rectify elusive errors in reward components, but EUREKA-S fails to do so.</p>
      <br></br>
  <img src="./static/images/fin2.png"
       class="architecture-image"
       alt="architecture-image image."
       style="width: 26%; display: block; margin: 0 auto;"/>
       <p>Two groups of weights generated by the reward weight initializer achieve Pareto solutions,
       therefore no further search is required, or only a more refined search may be necessary.</p>
       <br></br>
  <img src="./static/images/fin6.png"
       class="architecture-image"
       alt="architecture-image image."
       style="width: 70%; display: block; margin: 0 auto;"/>
       <p>In the 500x off experiment, the reward weight searcher quickly recognizes excessive energy consumption optimization and tries various adjustment. 
        However, EUREKA-M increases weights in a highly random manner ranther than decreasing the penalty of energy consumption.</p>
       <br></br>
  <img src="./static/images/fin3.png"
       class="architecture-image"
       alt="architecture-image image."
       style="width: 26%; display: block; margin: 0 auto;"/>
       <p>This figure shows the maximum value of
        w_service/w_ec in five weight groups during training,
       with the best performance among the five repetitions. The reward weight searcher adopts step sizes more flexibly, compared to GPT-4o w/o TLA and EUREKA-M. </p>
       <br></br>
  <img src="./static/images/fin4.png"
       class="architecture-image"
       alt="architecture-image image."
       style="width: 50%; display: block; margin: 0 auto;"/>
       <p> This table displays the number of iterations required to meet
        user demand.The experiments are performed 5 times,
        and the mean values and standard deviations are reported. Finally, on average only 5.2 iterations are needed to meet user requirements.</p>
      </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Examples. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h3 class="title is-3"><span class="dnerf">ERFSL</span> Prompt samples</h3>

        <object data="static/images/supplementary_LLM.pdf" width="100%" height="768px" type="application/pdf"></object>
      </div>
    </div>
  </div>
    <!--/ Examples. -->
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{xie2024llmrsearcher,
      title={Large Language Models as Efficient Reward Function Searchers for Custom-Environment Multi-Objective Reinforcement Learning},
      author={Xie, Guanwen and Xu, Jingzehua and and Yang, Yiyuan and Ren, Yong and Ding, Yimian and Zhang, Shuai},
      journal={arXiv preprint arXiv:2409.02428},
      year={2024}
    }
}</code></pre>
  </div>
</section>

<section class="section" id="BibTeX"></section>
  <div class="container is-max-desktop content">
    <h2 class="title"></h2>
    <img src="./static/images/FIN.jpg"
       class="architecture-image"
       alt="architecture-image image."
       style="width: 50%; display: block; margin: 0 auto;"/>
       <p><a href="https://en.wikipedia.org/wiki/Endro!">Â©ERP / ENDRO! Production Committee</a></p>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="https://arxiv.org/pdf/2409.02428.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/360ZMEM/LLMRsearcher-code" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            The code template borrows from <a rel="license"
                                                href="https://github.com/nerfies/nerfies.github.io">this repository</a>.
          </p>
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>



</body>
</html>
